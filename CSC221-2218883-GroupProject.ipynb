{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "589e9ab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching U.S. states population data from Wikipedia...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\trist\\AppData\\Local\\Temp\\ipykernel_66072\\3597811602.py:25: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  return pd.read_html(str(table))[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First 10 rows of the scraped data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State/federal district/territory/ division/region</th>\n",
       "      <th>#</th>\n",
       "      <th>2020 pop.</th>\n",
       "      <th>#.1</th>\n",
       "      <th>2010 pop.</th>\n",
       "      <th>#.2</th>\n",
       "      <th>2000 pop.</th>\n",
       "      <th>#.3</th>\n",
       "      <th>2010– 2020 change</th>\n",
       "      <th>Geo.  sort</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>15</td>\n",
       "      <td>7029917</td>\n",
       "      <td>14</td>\n",
       "      <td>6547629</td>\n",
       "      <td>13</td>\n",
       "      <td>6349097</td>\n",
       "      <td>21</td>\n",
       "      <td>7.4%</td>\n",
       "      <td>NEng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Connecticut</td>\n",
       "      <td>29</td>\n",
       "      <td>3605944</td>\n",
       "      <td>29</td>\n",
       "      <td>3574097</td>\n",
       "      <td>29</td>\n",
       "      <td>3405565</td>\n",
       "      <td>47</td>\n",
       "      <td>0.9%</td>\n",
       "      <td>NEng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>New Hampshire</td>\n",
       "      <td>41</td>\n",
       "      <td>1377529</td>\n",
       "      <td>42</td>\n",
       "      <td>1316470</td>\n",
       "      <td>41</td>\n",
       "      <td>1235786</td>\n",
       "      <td>30</td>\n",
       "      <td>4.6%</td>\n",
       "      <td>NEng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Maine</td>\n",
       "      <td>42</td>\n",
       "      <td>1362359</td>\n",
       "      <td>41</td>\n",
       "      <td>1328361</td>\n",
       "      <td>40</td>\n",
       "      <td>1274923</td>\n",
       "      <td>42</td>\n",
       "      <td>2.6%</td>\n",
       "      <td>NEng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rhode Island</td>\n",
       "      <td>43</td>\n",
       "      <td>1097379</td>\n",
       "      <td>43</td>\n",
       "      <td>1052567</td>\n",
       "      <td>43</td>\n",
       "      <td>1048319</td>\n",
       "      <td>31</td>\n",
       "      <td>4.3%</td>\n",
       "      <td>NEng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Vermont</td>\n",
       "      <td>49</td>\n",
       "      <td>643077</td>\n",
       "      <td>49</td>\n",
       "      <td>625741</td>\n",
       "      <td>49</td>\n",
       "      <td>608827</td>\n",
       "      <td>40</td>\n",
       "      <td>2.8%</td>\n",
       "      <td>NEng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>New England</td>\n",
       "      <td>9</td>\n",
       "      <td>15116205</td>\n",
       "      <td>9</td>\n",
       "      <td>14444865</td>\n",
       "      <td>9</td>\n",
       "      <td>13922517</td>\n",
       "      <td>7</td>\n",
       "      <td>4.6%</td>\n",
       "      <td>NEast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>New York</td>\n",
       "      <td>4</td>\n",
       "      <td>20201249</td>\n",
       "      <td>3</td>\n",
       "      <td>19378102</td>\n",
       "      <td>3</td>\n",
       "      <td>18976457</td>\n",
       "      <td>32</td>\n",
       "      <td>4.2%</td>\n",
       "      <td>MAtl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>5</td>\n",
       "      <td>13002700</td>\n",
       "      <td>6</td>\n",
       "      <td>12702379</td>\n",
       "      <td>6</td>\n",
       "      <td>12281054</td>\n",
       "      <td>43</td>\n",
       "      <td>2.4%</td>\n",
       "      <td>MAtl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>New Jersey</td>\n",
       "      <td>11</td>\n",
       "      <td>9288994</td>\n",
       "      <td>11</td>\n",
       "      <td>8791894</td>\n",
       "      <td>9</td>\n",
       "      <td>8414350</td>\n",
       "      <td>25</td>\n",
       "      <td>5.7%</td>\n",
       "      <td>MAtl</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  State/federal district/territory/ division/region   #  2020 pop. #.1  \\\n",
       "0                                     Massachusetts  15    7029917  14   \n",
       "1                                       Connecticut  29    3605944  29   \n",
       "2                                     New Hampshire  41    1377529  42   \n",
       "3                                             Maine  42    1362359  41   \n",
       "4                                      Rhode Island  43    1097379  43   \n",
       "5                                           Vermont  49     643077  49   \n",
       "6                                       New England   9   15116205   9   \n",
       "7                                          New York   4   20201249   3   \n",
       "8                                      Pennsylvania   5   13002700   6   \n",
       "9                                        New Jersey  11    9288994  11   \n",
       "\n",
       "  2010 pop. #.2 2000 pop. #.3 2010– 2020 change Geo.  sort  \n",
       "0   6547629  13   6349097  21              7.4%       NEng  \n",
       "1   3574097  29   3405565  47              0.9%       NEng  \n",
       "2   1316470  41   1235786  30              4.6%       NEng  \n",
       "3   1328361  40   1274923  42              2.6%       NEng  \n",
       "4   1052567  43   1048319  31              4.3%       NEng  \n",
       "5    625741  49    608827  40              2.8%       NEng  \n",
       "6  14444865   9  13922517   7              4.6%      NEast  \n",
       "7  19378102   3  18976457  32              4.2%       MAtl  \n",
       "8  12702379   6  12281054  43              2.4%       MAtl  \n",
       "9   8791894   9   8414350  25              5.7%       MAtl  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data successfully saved to CSC221-webscrape-data.csv\n"
     ]
    }
   ],
   "source": [
    "# U.S. States Population Data Scraper\n",
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# URL of the Wikipedia page with U.S. states population data\n",
    "URL = \"https://en.wikipedia.org/wiki/List_of_U.S._states_and_territories_by_population\"\n",
    "\n",
    "def fetch_wikipedia_page(url):\n",
    "    \"\"\"Fetch the Wikipedia page content.\"\"\"\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'\n",
    "    }\n",
    "    response = requests.get(url, headers=headers)\n",
    "    response.raise_for_status()\n",
    "    return response.text\n",
    "\n",
    "def parse_population_data(html_content):\n",
    "    \"\"\"Parse the HTML content to extract population data.\"\"\"\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    table = soup.find('table', {'class': 'wikitable sortable'})\n",
    "    if not table:\n",
    "        raise ValueError(\"Could not find the population data table on the page\")\n",
    "    return pd.read_html(str(table))[0]\n",
    "\n",
    "def clean_data(df):\n",
    "    \"\"\"Clean and process the population data.\"\"\"\n",
    "    df_clean = df.copy()\n",
    "    df_clean = df_clean.dropna(how='all')\n",
    "    df_clean.columns = [col.strip() for col in df_clean.columns]\n",
    "    state_col = df_clean.columns[1]\n",
    "    df_clean[state_col] = df_clean[state_col].str.replace(r'\\[.*?\\]', '', regex=True).str.strip()\n",
    "    pop_col = df_clean.columns[2]\n",
    "    df_clean[pop_col] = df_clean[pop_col].astype(str).str.replace(r'[^\\d]', '', regex=True).astype('int64')\n",
    "    return df_clean\n",
    "\n",
    "# Main execution\n",
    "print(\"Fetching U.S. states population data from Wikipedia...\")\n",
    "try:\n",
    "    # Fetch and process the data\n",
    "    html_content = fetch_wikipedia_page(URL)\n",
    "    df = parse_population_data(html_content)\n",
    "    df_clean = clean_data(df)\n",
    "    \n",
    "    # Display first 10 rows\n",
    "    print(\"\\nFirst 10 rows of the scraped data:\")\n",
    "    display(df_clean.head(10))\n",
    "    \n",
    "    # Save to CSV with the required filename\n",
    "    csv_filename = 'CSC221-webscrape-data.csv'\n",
    "    df_clean.to_csv(csv_filename, index=False)\n",
    "    print(f\"\\nData successfully saved to {csv_filename}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
